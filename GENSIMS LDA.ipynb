{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"preprocessed_train_cnn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.sample(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine the article and highlights \n",
    "# df['text'] = df['article'] + \" \" + df['highlights'] \n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the shape of the data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing data\n",
    "import spacy\n",
    "import re\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "stopword_list = list(STOP_WORDS)\n",
    "stop_words = stopword_list.words('english')\n",
    "\n",
    "nlp_en = spacy.load('en_core_web_lg')\n",
    "def preprocess(txt):\n",
    "    txt = txt.lower()   \n",
    "    txt = re.sub(r'[^a-zA-Z]', ' ', txt)\n",
    "    docs = nlp_en(txt)\n",
    "    word_list = [doc.lemma_ for doc in docs if doc.text \n",
    "                            not in stopword_list]\n",
    "    txt = \" \".join(word_list)\n",
    "    txt = txt.replace(\"-PRON-\", \"\")\n",
    "    txt = txt.replace(\"PRON\", \"\")\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepocessing the data using the following code and applying the code to get the pre-processed file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['cleaned_text']=df['text'].apply(preprocess)\n",
    "#cleaned_corpus = list(df['cleaned_text'])\n",
    "df = pd.read_csv(\"preprocessed_train_cnn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91377</td>\n",
       "      <td>Coronado, California  (CNN)Wisconsin Gov. Scot...</td>\n",
       "      <td>Walker is considering a run for the White Hous...</td>\n",
       "      <td>Coronado, California  (CNN)Wisconsin Gov. Scot...</td>\n",
       "      <td>coronado   california    cnn wisconsin gov   s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186398</td>\n",
       "      <td>Deep within a Cumbrian fell, my head torch fli...</td>\n",
       "      <td>Honister Slate Mine, near Keswick, has been tu...</td>\n",
       "      <td>Deep within a Cumbrian fell, my head torch fli...</td>\n",
       "      <td>deep cumbrian fall   head torch flicker cling ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>237390</td>\n",
       "      <td>By . Anna Edwards . PUBLISHED: . 11:18 EST, 28...</td>\n",
       "      <td>Virgin boss Sir Richard Branson hopes legal ch...</td>\n",
       "      <td>By . Anna Edwards . PUBLISHED: . 11:18 EST, 28...</td>\n",
       "      <td>anna edwards    publish           est      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>172530</td>\n",
       "      <td>(CNN) -- An international footballer who playe...</td>\n",
       "      <td>UAE international footballer Theyab Awana kill...</td>\n",
       "      <td>(CNN) -- An international footballer who playe...</td>\n",
       "      <td>cnn      international footballer play unite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>219419</td>\n",
       "      <td>A huge property grab by Chinese investors is p...</td>\n",
       "      <td>Developers selling directly to buyers in China...</td>\n",
       "      <td>A huge property grab by Chinese investors is p...</td>\n",
       "      <td>huge property grab chinese investor price uk h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            article  \\\n",
       "0       91377  Coronado, California  (CNN)Wisconsin Gov. Scot...   \n",
       "1      186398  Deep within a Cumbrian fell, my head torch fli...   \n",
       "2      237390  By . Anna Edwards . PUBLISHED: . 11:18 EST, 28...   \n",
       "3      172530  (CNN) -- An international footballer who playe...   \n",
       "4      219419  A huge property grab by Chinese investors is p...   \n",
       "\n",
       "                                          highlights  \\\n",
       "0  Walker is considering a run for the White Hous...   \n",
       "1  Honister Slate Mine, near Keswick, has been tu...   \n",
       "2  Virgin boss Sir Richard Branson hopes legal ch...   \n",
       "3  UAE international footballer Theyab Awana kill...   \n",
       "4  Developers selling directly to buyers in China...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Coronado, California  (CNN)Wisconsin Gov. Scot...   \n",
       "1  Deep within a Cumbrian fell, my head torch fli...   \n",
       "2  By . Anna Edwards . PUBLISHED: . 11:18 EST, 28...   \n",
       "3  (CNN) -- An international footballer who playe...   \n",
       "4  A huge property grab by Chinese investors is p...   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  coronado   california    cnn wisconsin gov   s...  \n",
       "1  deep cumbrian fall   head torch flicker cling ...  \n",
       "2     anna edwards    publish           est      ...  \n",
       "3    cnn      international footballer play unite...  \n",
       "4  huge property grab chinese investor price uk h...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining function to generate words after pre processing with gensim pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_words(texts):\n",
    "    tokens = []\n",
    "    for text in texts:\n",
    "        new = gensim.utils.simple_preprocess(text, deacc=True)\n",
    "        tokens.append(new)\n",
    "    return (tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a token list and storing the gensim's cleaned text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_list = gen_words(df['cleaned_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a dictionary file of the token list and applying that corpus to the lda model to get the topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.025*\"car\" + 0.013*\"police\" + 0.012*\"mr\" + 0.011*\"man\" + 0.010*\"drive\"')\n",
      "(1, '0.012*\"league\" + 0.011*\"club\" + 0.009*\"player\" + 0.009*\"goal\" + 0.009*\"season\"')\n",
      "(2, '0.013*\"water\" + 0.012*\"flight\" + 0.010*\"plane\" + 0.008*\"airport\" + 0.008*\"air\"')\n",
      "(3, '0.011*\"china\" + 0.010*\"world\" + 0.008*\"space\" + 0.007*\"north\" + 0.006*\"chinese\"')\n",
      "(4, '0.018*\"win\" + 0.016*\"game\" + 0.013*\"team\" + 0.012*\"world\" + 0.010*\"play\"')\n",
      "(5, '0.014*\"food\" + 0.014*\"animal\" + 0.011*\"dog\" + 0.010*\"find\" + 0.009*\"eat\"')\n",
      "(6, '0.009*\"wear\" + 0.009*\"look\" + 0.008*\"dress\" + 0.006*\"prince\" + 0.006*\"star\"')\n",
      "(7, '0.014*\"mr\" + 0.010*\"cent\" + 0.008*\"million\" + 0.008*\"pay\" + 0.007*\"minister\"')\n",
      "(8, '0.017*\"president\" + 0.013*\"obama\" + 0.010*\"state\" + 0.008*\"cnn\" + 0.006*\"house\"')\n",
      "(9, '0.014*\"health\" + 0.014*\"hospital\" + 0.011*\"doctor\" + 0.011*\"patient\" + 0.010*\"cancer\"')\n",
      "(10, '0.038*\"united\" + 0.033*\"van\" + 0.028*\"church\" + 0.020*\"africa\" + 0.016*\"ebola\"')\n",
      "(11, '0.022*\"court\" + 0.013*\"police\" + 0.010*\"case\" + 0.010*\"claim\" + 0.009*\"charge\"')\n",
      "(12, '0.013*\"attack\" + 0.013*\"al\" + 0.010*\"government\" + 0.009*\"group\" + 0.009*\"kill\"')\n",
      "(13, '0.024*\"police\" + 0.009*\"officer\" + 0.008*\"find\" + 0.008*\"shoot\" + 0.008*\"kill\"')\n",
      "(14, '0.019*\"family\" + 0.012*\"mother\" + 0.012*\"child\" + 0.011*\"old\" + 0.010*\"home\"')\n",
      "(15, '0.028*\"war\" + 0.016*\"military\" + 0.015*\"french\" + 0.015*\"soldier\" + 0.014*\"france\"')\n",
      "(16, '0.010*\"video\" + 0.009*\"film\" + 0.008*\"think\" + 0.008*\"write\" + 0.007*\"know\"')\n",
      "(17, '0.019*\"company\" + 0.009*\"user\" + 0.009*\"phone\" + 0.008*\"store\" + 0.008*\"customer\"')\n",
      "(18, '0.014*\"home\" + 0.014*\"house\" + 0.011*\"city\" + 0.009*\"hotel\" + 0.009*\"million\"')\n",
      "(19, '0.038*\"school\" + 0.031*\"child\" + 0.028*\"woman\" + 0.022*\"student\" + 0.013*\"girl\"')\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(tokens_list)\n",
    "corpus = [dictionary.doc2bow(tokens) for tokens in tokens_list]\n",
    "\n",
    "lda_model = models.LdaModel(corpus, num_topics=20, id2word=dictionary, passes=15, minimum_probability=0.01,minimum_phi_value=0.01,random_state=42)\n",
    "\n",
    "topics = lda_model.print_topics(num_words=5)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing pickle and dumping the LDA model in the pkl file to access large files in an easier way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle file \"C:\\Users\\tejes\\Desktop\\DATA SCIENCE\\lda_model_project.pkl\" created successfully.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "file_path = 'C:\\\\Users\\\\tejes\\\\Desktop\\\\DATA SCIENCE\\\\lda_model_project.pkl'\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(lda_model, file)\n",
    "print(f'Pickle file \"{file_path}\" created successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_article = \"\"\"The United States has warned Israel that it must fight more surgically and avoid further mass displacement of Palestinians in its war against Hamas to avoid a humanitarian crisis that overwhelms the world’s ability to respond, according to senior Biden administration officials.\n",
    "The White House has told Israel that replicating the scale of its bombardment in northern Gaza as it makes an expected push into southern Gaza once the recent pause in fighting ends would produce a crisis beyond the capacity of any humanitarian support network, the officials said on Monday night.\n",
    "The United Nations has said the fighting has already displaced most of Gaza’s population of 2.2 million.\n",
    "The statements are the Biden administration’s strongest warning to Israeli officials to date about the next phase of their military operation. For weeks, the White House has been careful to say it does not dictate how Israel conducts its military operations, but President Biden and senior members of his staff have grown more vocal as the humanitarian crisis has unfolded.\n",
    "They also come as the administration officials, who spoke on the condition of anonymity to discuss sensitive diplomatic issues, said they were ramping up humanitarian aid during the cease-fire that took effect last week, and expressed optimism that aid could continue even when fighting resumed.\n",
    "Among other things, American officials have told the Israelis that any coming military operations should not hamper the flow of power and water or impede the work of humanitarian sites such as hospitals and U.N.-supported shelters in south and central Gaza.\n",
    "The Israeli government was receptive to the requests, one official said.\n",
    "The cease-fire, to allow for the exchange of hostages held by Hamas and Palestinians taken prisoner by Israel, has allowed for the first extended break in the violence since the Oct. 7 attack by Hamas gunmen and other militant groups killed an estimated 1,200 people in Israel.\n",
    "Gazan health officials say at least 13,000 people were killed during the nearly 50-day Israeli bombardment and ground invasion that followed.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "stop_words = set(STOP_WORDS)\n",
    "nlp_en = spacy.load('en_core_web_lg')\n",
    "\n",
    "def preprocess(txt):\n",
    "    txt = txt.lower()  # Normalizing the text\n",
    "    txt = re.sub(r'[^a-zA-Z]', ' ', txt)\n",
    "    tokens = nlp_en(txt)\n",
    "    word_list = [token.lemma_ for token in tokens if token.text.lower() not in stop_words]\n",
    "    txt = \" \".join(word_list)\n",
    "    txt = txt.replace(\"-PRON-\", \"\")\n",
    "    txt = txt.replace(\"PRON\", \"\")\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'united states warn israel fight surgically avoid mass displacement palestinians war hamas avoid humanitarian crisis overwhelm world s ability respond   accord senior biden administration official   white house tell israel replicate scale bombardment northern gaza make expect push southern gaza recent pause fighting end produce crisis capacity humanitarian support network   official say monday night   united nations say fighting displace gaza s population      million   statement biden administration s strong warning israeli official date phase military operation   week   white house careful dictate israel conduct military operation   president biden senior member staff grow vocal humanitarian crisis unfold   come administration official   speak condition anonymity discuss sensitive diplomatic issue   say ramp humanitarian aid cease fire take effect week   express optimism aid continue fighting resume   thing   american official tell israelis come military operation hamper flow power water impede work humanitarian site hospital u n   support shelter south central gaza   israeli government receptive request   official say   cease fire   allow exchange hostage hold hama palestinians take prisoner israel   allow extend break violence oct     attack hamas gunman militant group kill estimate        people israel   gazan health official         people kill nearly     day israeli bombardment ground invasion follow'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_article_preprocessed = preprocess(test_article)\n",
    "test_article_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, [('the', 0.027276844), ('to', 0.018255092), ('of', 0.014844007), ('has', 0.012653661), ('that', 0.012100829), ('and', 0.011208369), ('The', 0.0109454775), ('in', 0.010855389), ('humanitarian', 0.010342313), ('officials', 0.008381763)])\n",
      "(1, [('the', 0.04489865), ('of', 0.023146037), ('and', 0.020569742), ('to', 0.019299924), ('that', 0.018755188), ('has', 0.01612614), ('The', 0.012642715), ('in', 0.012314057), ('as', 0.011343562), ('humanitarian', 0.0104722995)])\n",
      "(2, [('the', 0.049261674), ('of', 0.025619546), ('and', 0.020697745), ('to', 0.01765757), ('in', 0.014848999), ('has', 0.014607488), ('The', 0.014439242), ('humanitarian', 0.012167722), ('that', 0.012125441), ('officials', 0.00940645)])\n"
     ]
    }
   ],
   "source": [
    "tokenized_text = [text.split() for text in [test_article_preprocessed]]\n",
    "\n",
    "dictionary = corpora.Dictionary(tokenized_text)\n",
    "\n",
    "new_corpus = [dictionary.doc2bow(doc) for doc in tokenized_text]\n",
    "\n",
    "new_lda_model = lda_model[new_corpus]\n",
    "\n",
    "for doc_topics in new_lda_topics:\n",
    "    print(doc_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(0, '0.025*\"car\" + 0.013*\"police\" + 0.012*\"mr\" + 0.011*\"man\" + 0.010*\"drive\"')\n",
    "(1, '0.012*\"league\" + 0.011*\"club\" + 0.009*\"player\" + 0.009*\"goal\" + 0.009*\"season\"')\n",
    "(2, '0.013*\"water\" + 0.012*\"flight\" + 0.010*\"plane\" + 0.008*\"airport\" + 0.008*\"air\"')\n",
    "(3, '0.011*\"china\" + 0.010*\"world\" + 0.008*\"space\" + 0.007*\"north\" + 0.006*\"chinese\"')\n",
    "(4, '0.018*\"win\" + 0.016*\"game\" + 0.013*\"team\" + 0.012*\"world\" + 0.010*\"play\"')\n",
    "(5, '0.014*\"food\" + 0.014*\"animal\" + 0.011*\"dog\" + 0.010*\"find\" + 0.009*\"eat\"')\n",
    "(6, '0.009*\"wear\" + 0.009*\"look\" + 0.008*\"dress\" + 0.006*\"prince\" + 0.006*\"star\"')\n",
    "(7, '0.014*\"mr\" + 0.010*\"cent\" + 0.008*\"million\" + 0.008*\"pay\" + 0.007*\"minister\"')\n",
    "(8, '0.017*\"president\" + 0.013*\"obama\" + 0.010*\"state\" + 0.008*\"cnn\" + 0.006*\"house\"')\n",
    "(9, '0.014*\"health\" + 0.014*\"hospital\" + 0.011*\"doctor\" + 0.011*\"patient\" + 0.010*\"cancer\"')\n",
    "(10, '0.038*\"united\" + 0.033*\"van\" + 0.028*\"church\" + 0.020*\"africa\" + 0.016*\"ebola\"')\n",
    "(11, '0.022*\"court\" + 0.013*\"police\" + 0.010*\"case\" + 0.010*\"claim\" + 0.009*\"charge\"')\n",
    "(12, '0.013*\"attack\" + 0.013*\"al\" + 0.010*\"government\" + 0.009*\"group\" + 0.009*\"kill\"')\n",
    "(13, '0.024*\"police\" + 0.009*\"officer\" + 0.008*\"find\" + 0.008*\"shoot\" + 0.008*\"kill\"')\n",
    "(14, '0.019*\"family\" + 0.012*\"mother\" + 0.012*\"child\" + 0.011*\"old\" + 0.010*\"home\"')\n",
    "(15, '0.028*\"war\" + 0.016*\"military\" + 0.015*\"french\" + 0.015*\"soldier\" + 0.014*\"france\"')\n",
    "(16, '0.010*\"video\" + 0.009*\"film\" + 0.008*\"think\" + 0.008*\"write\" + 0.007*\"know\"')\n",
    "(17, '0.019*\"company\" + 0.009*\"user\" + 0.009*\"phone\" + 0.008*\"store\" + 0.008*\"customer\"')\n",
    "(18, '0.014*\"home\" + 0.014*\"house\" + 0.011*\"city\" + 0.009*\"hotel\" + 0.009*\"million\"')\n",
    "(19, '0.038*\"school\" + 0.031*\"child\" + 0.028*\"woman\" + 0.022*\"student\" + 0.013*\"girl\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
